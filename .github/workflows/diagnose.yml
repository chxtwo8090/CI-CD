# .github/workflows/diagnose.yml
name: "EKS Deployment Diagnoser"

on: [workflow_dispatch] # GitHub 웹에서 수동으로 실행

permissions:
  id-token: write # OIDC 인증

env:
  AWS_REGION: ap-northeast-2
  EKS_CLUSTER_NAME: chan-gyu-stock-eks
  
jobs:
  diagnose:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      # 1. OIDC를 통한 AWS 인증
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }} 
          aws-region: ${{ env.AWS_REGION }}

      # 2. Kubeconfig 업데이트
      - name: Update Kubeconfig
        run: aws eks update-kubeconfig --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }}
      
      # 3. 모든 Pod의 상태 진단 (Timeout 원인 파악)
      - name: Delete and Recreate ALB Controller
        run: |
          echo "--- Attempting to delete ALB Controller Pod ---"
          # LBC Pod의 이름 찾기
          LBC_POD_NAME=$(kubectl get pod -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller -o jsonpath='{.items[0].metadata.name}' || echo "")
          
          if [ -n "$LBC_POD_NAME" ]; then
            echo "Found LBC Pod: $LBC_POD_NAME. Deleting it now."
            # Pod 삭제 명령 (Deployment가 자동으로 다시 생성함)
            kubectl delete pod $LBC_POD_NAME -n kube-system
          else
            echo "LBC Pod not found. It might be stuck in a failed state."
          fi
          
          echo "Waiting 30 seconds for new Pod to initialize..."
          sleep 30
          
          # Pod 상태 최종 확인
          kubectl get pods -A -o wide
          
      # 4. Ingress Controller Pod 상태 확인 (ALB 생성 주체)
      - name: Check Ingress Controller Status
        run: |
          echo "--- Ingress Controller Pod Status ---"
          # ⬇️ [수정]: LBC Pod 상태 확인
          kubectl get pods -n kube-system | grep alb